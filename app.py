# app.py
# Root API: https://binkhoale1812-poptech-cleaner.hf.space/
# Usages: 
## https://binkhoale1812-poptech-cleaner.hf.space/fetch?Password=...
## https://binkhoale1812-poptech-cleaner.hf.space/load?Password=...
## https://binkhoale1812-poptech-cleaner.hf.space/delete?Password=...

import os, json, signal, logging, threading, time
from datetime import datetime, timedelta
from collections import deque 

import paho.mqtt.client as mqtt
from dotenv import load_dotenv
import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.linear_model import LinearRegression
from pymongo import MongoClient, UpdateOne
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse, FileResponse
import uvicorn

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ENV CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
load_dotenv()

BROKER       = os.getenv("BROKER")
PORT         = int(os.getenv("PORT", 1883))
USERNAME     = os.getenv("USERNAME")
PASSWORD     = os.getenv("PASSWORD")
MQTT_TOPIC   = os.getenv("MQTT_TOPIC", "device/socket/reply/#")

MONGO_URI    = os.getenv("MONGO_URI")
MONGO_DB     = os.getenv("MONGO_DB", "poptech")
MONGO_COL    = os.getenv("MONGO_COLLECTION", "device_clean")
FETCH_PASS   = os.getenv("FETCH_PASSWORD")

# Tham s·ªë x·ª≠ l√Ω (th·ªùi gian)
EXPECTED_INTERVAL_SEC = int(os.getenv("EXPECTED_INTERVAL_SEC", 30))
TOLERANCE_SEC         = int(os.getenv("TOLERANCE_SEC", 10))
BUFFER_SECONDS        = int(os.getenv("BUFFER_SECONDS", 4 * 3600))   # 4 gi·ªù
BACKFILL_INTERVAL     = int(os.getenv("BACKFILL_INTERVAL", 10))      # 10 gi√¢y

RAW_CHECKPOINT_PATH   = os.getenv("RAW_CHECKPOINT_PATH", "cache/checkpoint_raw.csv")
EXPORT_CSV_PATH       = "mongo_cleaned_export.csv"
os.makedirs(os.path.dirname(RAW_CHECKPOINT_PATH), exist_ok=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ LOGGING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s ‚Äî %(name)s ‚Äî %(levelname)s ‚Äî %(message)s",
    force=True
)
logger = logging.getLogger("poptech-cleaner")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ GLOBALS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
win_len      = BUFFER_SECONDS // EXPECTED_INTERVAL_SEC + 200
window       = deque(maxlen=win_len)           # l∆∞u 4 gi·ªù g·∫ßn nh·∫•t
stop_event   = threading.Event()
app          = FastAPI()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ UTILITIES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ƒê·∫£m b·∫£o gi√° tr·ªã l√† float, n·∫øu kh√¥ng flag NaN
def safe_float(x):
    try: return float(x)
    except: return np.nan

def parse_row(ts: str, topic: str, payload: str):
    """Tr·∫£ v·ªÅ dict ƒë√£ parse ho·∫∑c None n·∫øu kh√¥ng h·ª£p l·ªá."""
    try:
        j = json.loads(payload.replace('""', '"'))
        if not topic.startswith("device/socket/reply/"):
            return None
        if not isinstance(j.get("data", []), list):
            return None
        v, a, w, c = (j["data"] + [None] * 4)[:4]
        # b·ªè frame idle (all 0)
        if all(x in (0, None) for x in (a, w, c)):
            return None
        return {
            "timestamp": ts,
            "id": j.get("id"),
            "imei": j.get("imei"),
            "type": j.get("type"),
            "voltage": safe_float(v),
            "current": safe_float(a),
            "power": safe_float(w),
            "consume": safe_float(c)
        }
    except Exception:
        return None

# T·∫£i d·ªØ li·ªáu m·ªõi l√™n DB
def upsert_mongo(docs):
    if not docs:
        return
    try:
        client = MongoClient(MONGO_URI)
        col    = client[MONGO_DB][MONGO_COL]
        col.create_index("timestamp", unique=True)
        ops = [UpdateOne({"_id": d["timestamp"]}, {"$set": d}, upsert=True) for d in docs]
        col.bulk_write(ops, ordered=False)
    except Exception as e:
        logger.error(f"‚ùå Mongo error: {e}")

# Ch√®n gi√° tr·ªã t·ªïng th·ªÉ
def fill_missing(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df.sort_values("timestamp", inplace=True)
    # T·ªïng th·ªùi gian d·ª± ki·∫øn gi·ªØa session
    expected = timedelta(seconds=EXPECTED_INTERVAL_SEC)
    tol      = timedelta(seconds=TOLERANCE_SEC)
    # L·ªçc l·ªói v√† tr·ªëng
    rows = [df.iloc[0]]
    for i in range(1, len(df)):
        prev, curr = df.iloc[i-1]["timestamp"], df.iloc[i]["timestamp"]
        rows.append(df.iloc[i])
        if curr - prev > expected + tol:
            for j in range(1, int(round((curr - prev) / expected))):
                gap_ts = prev + j * expected
                gap = df.iloc[i-1].copy()
                gap["timestamp"] = gap_ts
                for col in ["voltage", "current", "power", "consume"]:
                    gap[col] = np.nan
                rows.insert(-1, gap)
    # Sort v·ªõi ts l√† identifier
    df = pd.DataFrame(rows).sort_values("timestamp").reset_index(drop=True)
    df["consume_clean"] = df["consume"]
    df.loc[(df["consume"] < 0) | (df["consume"].diff() < 0), "consume_clean"] = np.nan
    # Impute 3 gi√° tr·ªã c√≤n l·∫°i v·ªõi KNNImputer
    non_missing = df[["voltage","current","power"]].dropna().shape[0]
    k = min(3, max(1, non_missing))
    imputer = KNNImputer(n_neighbors=k)
    df[["voltage", "current", "power"]] = imputer.fit_transform(df[["voltage", "current", "power"]])
    # Train v√† pred fit v·ªõi LinearRegression
    train = df[df["consume_clean"].notna()]
    pred  = df[df["consume_clean"].isna()]
    if not train.empty and not pred.empty:
        model = LinearRegression().fit(train[["voltage","current","power"]], train["consume_clean"])
        try:
            y_hat = model.predict(pred[["voltage","current","power"]])
            df.loc[pred.index, "consume_clean"] = pd.Series(y_hat, index=pred.index)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Primary model error: {e}")
    # N·∫øu c√≤n gi√° tr·ªã tr·ªëng sau b·ªô l·ªçc ƒë·∫ßu, t√°i sd LinearRegression v√† d·ª± ƒëo√°n tr√™n ts + t·ªïng tg gi·ªØa session
    still = df[df["consume_clean"].isna()]
    if not still.empty:
        logger.warning(f"‚ö†Ô∏è {len(still)} rows still missing ‚Üí timestamp fallback")
        df["ts_sec"] = (df["timestamp"] - df["timestamp"].min()).dt.total_seconds()
        fb_train = df[df["consume_clean"].notna()]
        fb_pred  = df[df["consume_clean"].isna()]
        fb_pred  = fb_pred[fb_pred["ts_sec"].notna()].drop_duplicates(subset="timestamp")
        if not fb_train.empty and not fb_pred.empty:
            fb_model = LinearRegression().fit(fb_train[["ts_sec"]], fb_train["consume_clean"])
            y_fb = fb_model.predict(fb_pred[["ts_sec"]])
            df.loc[fb_pred.index, "consume_clean"] = pd.Series(y_fb, index=fb_pred.index)
        df.drop(columns=["ts_sec"], inplace=True)
    # Gi√° tr·ªã cu·ªëi v√† th·∫£i gi√° tr·ªã th·ª´a
    df["consume"] = df["consume_clean"]
    # ƒê√°nh d·∫•u nh·ªØng b·∫£n ghi v·∫´n c√≤n thi·∫øu consume
    # Khi h√†m tr·∫£ v·ªÅ, m·ªói d√≤ng s·∫Ω c√≥ need_backfill = True/False.
    df.loc[:, "need_backfill"] = df["consume"].isna()
    return df.drop(columns=["consume_clean"])

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MQTT CALLBACKS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def on_connect(client, userdata, flags, rc):
    if rc == 0:
        logger.info("‚úÖ MQTT connected")
        client.subscribe(MQTT_TOPIC)
    else:
        logger.error(f"‚ùå MQTT connect failed: {rc}")

# Pipe ch√≠nh v√† debug
def on_message(client, userdata, msg):
    ts = datetime.utcnow().isoformat()
    payload = msg.payload.decode(errors="replace")
    with open(RAW_CHECKPOINT_PATH,"a",encoding="utf-8") as f:
        f.write(f"{ts},{msg.topic},\"{payload}\"\n")
    row = parse_row(ts,msg.topic,payload)
    if row is None: return
    # Gh√©p v√†o c·ª≠a s·ªï v√† fill ngay
    df_win = pd.DataFrame(window)
    df_new = pd.concat([df_win, pd.DataFrame([row])], ignore_index=True)
    df_filled = fill_missing(df_new.tail(2))  # ch·ªâ c·∫ßn b·∫£n ghi tr∆∞·ªõc & m·ªõi
    row_clean = df_filled.tail(1).to_dict("records")[0]
    row_clean["need_backfill"] = pd.isna(row_clean["consume"])
    # G·∫Øn gi√° tr·ªã clean v√†o window session
    window.append(row_clean)
    upsert_mongo([row_clean])
    logger.info(f"üì• Stored row {row_clean['timestamp']}")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ BACK-FILL WORKER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def backfill_worker():
    while not stop_event.is_set():
        time.sleep(BACKFILL_INTERVAL)
        df_win = pd.DataFrame(window)
        pending_mask = df_win["need_backfill"]
        if not pending_mask.any():
            continue
        idxs = df_win[pending_mask].index
        cols = ["voltage", "current", "power"]
        imputer = KNNImputer(n_neighbors=3)
        df_win[cols] = imputer.fit_transform(df_win[cols])
        train = df_win[~pending_mask]
        if train.empty:
            continue
        model = LinearRegression().fit(train[cols], train["consume"])
        df_win.loc[idxs, "consume"] = model.predict(df_win.loc[idxs, cols])
        df_win.loc[idxs, "need_backfill"] = False
        # update deque
        for i in idxs:
            window[i].update(df_win.loc[i].to_dict())
        # Upload and merge current on Mongo
        upsert_mongo([window[i] for i in idxs])
        logger.info(f"üîÑ Back-filled {len(idxs)} rows")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ FASTAPI ENDPOINTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@app.get("/fetch")
def fetch(Password: str):
    if Password != FETCH_PASS:
        raise HTTPException(status_code=401)
    logger.info("‚úÖ Fetch request received")
    client = MongoClient(MONGO_URI)
    data = list(client[MONGO_DB][MONGO_COL].find({}, {"_id": 0}))
    return JSONResponse(data)

@app.get("/delete")
def delete(Password: str):
    if Password != FETCH_PASS:
        raise HTTPException(status_code=401)
    client = MongoClient(MONGO_URI)
    count = client[MONGO_DB][MONGO_COL].delete_many({}).deleted_count
    logger.info("‚ö†Ô∏è Delete request received")
    return {"message": f"üß® Deleted {count} rows from MongoDB."}

@app.get("/load")
def load(Password: str):
    if Password != FETCH_PASS:
        raise HTTPException(status_code=401)
    client = MongoClient(MONGO_URI)
    df = pd.DataFrame(list(client[MONGO_DB][MONGO_COL].find({}, {"_id": 0})))
    if df.empty:
        raise HTTPException(status_code=404, detail="No data found.")
    logger.info("‚úÖ Download request received")
    df.to_csv(EXPORT_CSV_PATH, index=False)
    return FileResponse(EXPORT_CSV_PATH, filename="poptech_cleaned_data.csv", media_type="text/csv")

@app.get("/healthz")
def health():
    return {"status": "ok"}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ BOOTSTRAP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def mqtt_main():
    client = mqtt.Client()
    client.username_pw_set(USERNAME, PASSWORD)
    client.on_connect = on_connect
    client.on_message = on_message
    client.connect(BROKER, PORT, 60)
    client.loop_forever()

# Handle parallel threads
if __name__ == "__main__":
    # Set signal handlers in main thread
    def handle_exit(sig, _):
        logger.info("üõë Shutdown signal received")
        stop_event.set()
    for s in [signal.SIGINT, signal.SIGTERM]:
        signal.signal(s, handle_exit)
    # Handle data ingestion from MQTT broker, and backfiller
    threading.Thread(target=backfill_worker, daemon=True).start()   # qu√©t back-fill 10s/l·∫ßn
    threading.Thread(target=mqtt_main, daemon=True).start()
    uvicorn.run(app, host="0.0.0.0", port=7860)

